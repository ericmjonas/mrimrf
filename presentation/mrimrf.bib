
@article{metropolis_equation_1953,
	title = {Equation of State Calculations by Fast Computing Machines},
	volume = {21},
	url = {http://link.aip.org/link/?JCP/21/1087/1},
	doi = {10.1063/1.1699114},
	number = {6},
	journal = {The Journal of Chemical Physics},
	author = {Nicholas Metropolis and Arianna W. Rosenbluth and Marshall N. Rosenbluth and Augusta H. Teller and Edward Teller},
	month = jun,
	year = {1953},
	pages = {1087--1092}
},

@inbook{geman_stochastic_1990,
	title = {Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images},
	isbn = {1-55860-125-2},
	url = {http://portal.acm.org/citation.cfm?id=85346},
	booktitle = {Readings in uncertain reasoning},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {S. Geman and D. Geman},
	year = {1990},
	pages = {452--472}
},

@article{kschischang_factor_2001,
	title = {Factor graphs and the sum-product algorithm},
	volume = {47},
	issn = {0018-9448},
	doi = {10.1109/18.910572},
	abstract = {Algorithms that must deal with complicated global functions of
many variables often exploit the manner in which the given functions
factor as a product of “local” functions, each of which
depends on a subset of the variables. Such a factorization can be
visualized with a bipartite graph that we call a factor graph, In this
tutorial paper, we present a generic message-passing algorithm, the
sum-product algorithm, that operates in a factor graph. Following a
single, simple computational rule, the sum-product algorithm
computes-either exactly or approximately-various marginal functions
derived from the global function. A wide variety of algorithms developed
in artificial intelligence, signal processing, and digital
communications can be derived as specific instances of the sum-product
algorithm, including the forward/backward algorithm, the Viterbi
algorithm, the iterative “turbo” decoding algorithm, Pearl's
(1988) belief propagation algorithm for Bayesian networks, the Kalman
filter, and certain fast Fourier transform {(FFT)} algorithms},
	number = {2},
	journal = {Information Theory, {IEEE} Transactions on},
	author = {{F.R.} Kschischang and {B.J.} Frey and {H.-A.} Loeliger},
	year = {2001},
	keywords = {artificial {intelligence,Bayesian} networks,belief networks,belief propagation algorithm,bipartite graph,computational rule,digital communication,digital communications,factor graphs,factorization,fast Fourier transform,fast Fourier {transforms,FFT} algorithms,forward/backward algorithm,functional analysis,generic message-passing algorithm,global function,global functions,graph theory,hidden Markov {models,HMM,iterative} decoding,iterative turbo decoding {algorithm,Kalman} {filter,Kalman} filters,local functions,marginal functions,message passing,signal processing,sum-product algorithm,turbo {codes,Viterbi} {algorithm,Viterbi} decoding},
	pages = {498--519}
},

@misc{_merl_????,
	title = {{MERL} – {TR1999-008} – Markov networks for low-level vision},
	url = {http://www.merl.com/papers/TR99-08/}
},

@article{freeman_markov_1999,
	title = {Markov networks for low-level vision},
	volume = {{TR99}},
	number = {08},
	journal = {{MERL} Tech Report},
	author = {William Freeman and Egon Pasztor},
	month = feb,
	year = {1999}
},

@article{swendsen_replica_1986,
	title = {Replica Monte Carlo Simulation of {Spin-Glasses}},
	volume = {57},
	url = {http://link.aps.org/abstract/PRL/v57/p2607},
	doi = {{10.1103/PhysRevLett.57.2607}},
	abstract = {A new Monte Carlo method is presented for simulations of systems with quenched random interactions. The approach greatly reduces the long correlation times characteristic of standard methods, allowing the investigation of lower temperatures with less computer time than previously necessary.},
	number = {21},
	journal = {Physical Review Letters},
	author = {Robert H. Swendsen and {Jian-Sheng} Wang},
	month = nov,
	year = {1986},
	note = {Copyright {(C)} 2009 The American Physical Society; Please report any problems to prola@aps.org},
	pages = {2607}
},

@article{zhuowen_tu_image_2002,
	title = {Image segmentation by data-driven Markov chain Monte Carlo},
	volume = {24},
	issn = {0162-8828},
	doi = {10.1109/34.1000239},
	abstract = {This paper presents a computational paradigm called {Data-Driven}
Markov Chain Monte Carlo {(DDMCMC)} for image segmentation in the Bayesian
statistical framework. The paper contributes to image segmentation in
four aspects. First, it designs efficient and well-balanced Markov Chain
dynamics to explore the complex solution space and, thus, achieves a
nearly global optimal solution independent of initial segmentations.
Second, it presents a mathematical principle and a K-adventurers
algorithm for computing multiple distinct solutions from the Markov
chain sequence and, thus, it incorporates intrinsic ambiguities in image
segmentation. Third, it utilizes data-driven (bottom-up) techniques,
such as clustering and edge detection, to compute importance proposal
probabilities, which drive the Markov chain dynamics and achieve
tremendous speedup in comparison to the traditional jump-diffusion
methods. Fourth, the {DDMCMC} paradigm provides a unifying framework in
which the role of many existing segmentation algorithms, such as, edge
detection, clustering, region growing, split-merge, snake/balloon, and
region competition, are revealed as either realizing Markov chain
dynamics or computing importance proposal probabilities. Thus, the
{DDMCMC} paradigm combines and generalizes these segmentation methods in a
principled way. The {DDMCMC} paradigm adopts seven parametric and
nonparametric image models for intensity and color at various regions.
We test the {DDMCMC} paradigm extensively on both color and gray-level
images and some results are reported in this paper},
	number = {5},
	journal = {Pattern Analysis and Machine Intelligence, {IEEE} Transactions on},
	author = {Zhuowen Tu and {Song-Chun} Zhu},
	year = {2002},
	keywords = {Bayesian statistical framework,clustering,computational paradigm,data {clustering,Data-Driven} Markov Chain Monte Carlo,edge detection,image {segmentation,Markov} chain {sequence,Markov} {processes,Markov} random {field,Monte} Carlo methods,region competition,snake/balloon,split-merge},
	pages = {657--673}
},

@article{liang_evolutionary_2000,
	title = {Evolutionary Monte Carlo: Applications to C\_p Model Sampling and Change Point Problem},
	volume = {10},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.15.4052},
	doi = {10.1.1.15.4052},
	journal = {{STATISTICA} {SINICA}},
	author = {Faming Liang and Wing Hung Wong},
	year = {2000},
	pages = {317---342}
},

@article{lei_ying_unwrapping_2006,
	title = {Unwrapping of {MR} phase images using a Markov random field model},
	volume = {25},
	issn = {0278-0062},
	doi = {{10.1109/TMI.2005.861021}},
	abstract = {Phase unwrapping is an important problem in many magnetic resonance imaging applications, such as field mapping and flow imaging. The challenge in two-dimensional phase unwrapping lies in distinguishing jumps due to phase wrapping from those due to noise and/or abrupt variations in the actual function. This paper addresses this problem using a Markov random field to model the true phase function, whose parameters are determined by maximizing the a posteriori probability. To reduce the computational complexity of the optimization procedure, an efficient algorithm is also proposed for parameter estimation using a series of dynamic programming connected by the iterated conditional modes. The proposed method has been tested with both simulated and experimental data, yielding better results than some of the state-of-the-art method (e.g., the popular least-squares method) in handling noisy phase images with rapid phase variations.},
	number = {1},
	journal = {Medical Imaging, {IEEE} Transactions on},
	author = {Lei Ying and {Zhi-Pei} Liang and {D.C.} Munson and R. Koetter and {B.J.} Frey},
	year = {2006},
	keywords = {a posteriori {probability,Bayesian} estimation,biomedical {MRI,computational} complexity,field mapping,flow imaging,least squares approximations,least-squares method,magnetic resonance {imaging,Markov} {processes,Markov} random {field,Markov} random field model,medical image {processing,MR} phase images,optimisation,optimization,parameter estimation,phase unwrapping},
	pages = {128--136}
},

@book{liu_monte_2002,
	edition = {Corrected},
	title = {Monte Carlo Strategies in Scientific Computing},
	publisher = {Springer},
	author = {Jun S. Liu},
	month = oct,
	year = {2002}
},

@article{kschischang_factor_2001-1,
	title = {Factor graphs and the sum-product algorithm},
	volume = {47},
	issn = {0018-9448},
	doi = {10.1109/18.910572},
	abstract = {Algorithms that must deal with complicated global functions of
many variables often exploit the manner in which the given functions
factor as a product of “local” functions, each of which
depends on a subset of the variables. Such a factorization can be
visualized with a bipartite graph that we call a factor graph, In this
tutorial paper, we present a generic message-passing algorithm, the
sum-product algorithm, that operates in a factor graph. Following a
single, simple computational rule, the sum-product algorithm
computes-either exactly or approximately-various marginal functions
derived from the global function. A wide variety of algorithms developed
in artificial intelligence, signal processing, and digital
communications can be derived as specific instances of the sum-product
algorithm, including the forward/backward algorithm, the Viterbi
algorithm, the iterative “turbo” decoding algorithm, Pearl's
(1988) belief propagation algorithm for Bayesian networks, the Kalman
filter, and certain fast Fourier transform {(FFT)} algorithms},
	number = {2},
	journal = {Information Theory, {IEEE} Transactions on},
	author = {{F.R.} Kschischang and {B.J.} Frey and {H.-A.} Loeliger},
	year = {2001},
	keywords = {artificial {intelligence,Bayesian} networks,belief networks,belief propagation algorithm,bipartite graph,computational rule,digital communication,digital communications,factor graphs,factorization,fast Fourier transform,fast Fourier {transforms,FFT} algorithms,forward/backward algorithm,functional analysis,generic message-passing algorithm,global function,global functions,graph theory,hidden Markov {models,HMM,iterative} decoding,iterative turbo decoding {algorithm,Kalman} {filter,Kalman} filters,local functions,marginal functions,message passing,signal processing,sum-product algorithm,turbo {codes,Viterbi} {algorithm,Viterbi} decoding},
	pages = {498--519}
}